{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import extractor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Extraction Complete.\n"
     ]
    }
   ],
   "source": [
    "# data extraction\n",
    "X_nik = extractor.features(13,\"data/nikhil/\")\n",
    "X_nik= pd.DataFrame(X_nik)\n",
    "X_nik['Class']=0\n",
    "\n",
    "X_ark = extractor.features(13,\"data/arka/\")\n",
    "X_ark= pd.DataFrame(X_ark)\n",
    "X_ark['Class']=1\n",
    "\n",
    "X_prv = extractor.features(13,\"data/prativa/\")\n",
    "X_prv= pd.DataFrame(X_prv)\n",
    "X_prv['Class']=2\n",
    "\n",
    "X_deb = extractor.features(13,\"data/debalina/\")\n",
    "X_deb= pd.DataFrame(X_deb)\n",
    "X_deb['Class']=3\n",
    "\n",
    "X_arn = extractor.features(13,\"data/aryendra/\")\n",
    "X_arn= pd.DataFrame(X_arn)\n",
    "X_arn['Class']=4\n",
    "print('\\nData Extraction Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining training and testing data\n",
    "X_nik_train = X_nik[:int(X_nik.shape[0]*0.8)]\n",
    "X_nik_test = X_nik[int(X_nik.shape[0]*0.8):]\n",
    "\n",
    "X_ark_train = X_ark[:int(X_ark.shape[0]*0.8)]\n",
    "X_ark_test = X_ark[int(X_ark.shape[0]*0.8):]\n",
    "\n",
    "X_prv_train = X_prv[:int(X_prv.shape[0]*0.8)]\n",
    "X_prv_test = X_prv[int(X_prv.shape[0]*0.8):]\n",
    "\n",
    "X_deb_train = X_deb[:int(X_deb.shape[0]*0.8)]\n",
    "X_deb_test = X_deb[int(X_deb.shape[0]*0.8):]\n",
    "\n",
    "X_arn_train = X_arn[:int(X_arn.shape[0]*0.8)]\n",
    "X_arn_test = X_arn[int(X_arn.shape[0]*0.8):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pre-processing Done.\n"
     ]
    }
   ],
   "source": [
    "X_train=X_nik_train.append([X_ark_train,X_prv_train,X_deb_train,X_arn_train])\n",
    "X_test=X_nik_test.append([X_ark_test,X_prv_test,X_deb_test,X_arn_test])\n",
    "\n",
    "y_train=X_train[['Class']]\n",
    "y_test=X_test[['Class']]\n",
    "X_data=X_train.append(X_test)\n",
    "X_data = X_data.reset_index(drop=True)\n",
    "y_data=y_train.append(y_test)\n",
    "y_data = y_data.reset_index(drop=True)\n",
    "print('\\nPre-processing Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of different classes in Train set:\n",
      "3    1004\n",
      "1     769\n",
      "4     651\n",
      "2     635\n",
      "0     520\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nCount of different classes in Train set:')\n",
    "print(X_train['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of different classes in Test set:\n",
      "3    251\n",
      "1    193\n",
      "4    163\n",
      "2    159\n",
      "0    131\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nCount of different classes in Test set:')\n",
    "print(X_test['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats=[c for c in X_train.columns if c!='Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Implementing Gaussian Naive Bayes Model.\n"
     ]
    }
   ],
   "source": [
    "# Train classifier\n",
    "print('\\nImplementing Gaussian Naive Bayes Model.')\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(\n",
    "    X_train[feats].values,\n",
    "    y_train['Class']\n",
    ")\n",
    "y_pred = gnb.predict(X_test[feats].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of mislabeled points out of a total 897 points : 453, Accuracy: 49.49833%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of mislabeled points out of a total {} points : {}, Accuracy: {:05.5f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (X_test[\"Class\"] != y_pred).sum(),\n",
    "          100*(1-(X_test[\"Class\"] != y_pred).sum()/X_test.shape[0])\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5)\n",
    "clf = GaussianNB()\n",
    "X_data=X_data.values\n",
    "y_data=y_data.values\n",
    "accuracy=0\n",
    "for traincv, testcv in cv.split(X_data):\n",
    "        clf.fit(X_data[traincv], y_data[traincv])\n",
    "        train_predictions = clf.predict(X_data[testcv])\n",
    "        acc = accuracy_score(y_data[testcv], train_predictions)\n",
    "        accuracy+= acc\n",
    "        #print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5 Fold Cross Validation Accuracy on Training Set: 0.7899441340782123\n"
     ]
    }
   ],
   "source": [
    "print('\\n5 Fold Cross Validation Accuracy on Training Set: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Extraction Complete.\n",
      "\n",
      "Pre-processing Done.\n",
      "\n",
      "Count of different classes in Train set:\n",
      "7    19072\n",
      "5    10792\n",
      "6     3153\n",
      "3     1004\n",
      "1      769\n",
      "4      651\n",
      "2      635\n",
      "0      520\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Count of different classes in Test set:\n",
      "7    4769\n",
      "5    2699\n",
      "6     789\n",
      "3     251\n",
      "1     193\n",
      "4     163\n",
      "2     159\n",
      "0     131\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Implementing Gaussian Naive Bayes Model.\n",
      "\n",
      "Number of mislabeled points out of a total 9154 points : 1511, Accuracy: 83.49355%\n",
      "\n",
      "5 Fold Cross Validation Accuracy on Training Set: 3.3695081967213114\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import extractor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# data extraction\n",
    "X_nik = extractor.features(13,\"data/nikhil/\")\n",
    "X_nik= pd.DataFrame(X_nik)\n",
    "X_nik['Class']=0\n",
    "\n",
    "X_ark = extractor.features(13,\"data/arka/\")\n",
    "X_ark= pd.DataFrame(X_ark)\n",
    "X_ark['Class']=1\n",
    "\n",
    "X_prv = extractor.features(13,\"data/prativa/\")\n",
    "X_prv= pd.DataFrame(X_prv)\n",
    "X_prv['Class']=2\n",
    "\n",
    "X_deb = extractor.features(13,\"data/debalina/\")\n",
    "X_deb= pd.DataFrame(X_deb)\n",
    "X_deb['Class']=3\n",
    "\n",
    "X_arn = extractor.features(13,\"data/aryendra/\")\n",
    "X_arn= pd.DataFrame(X_arn)\n",
    "X_arn['Class']=4\n",
    "\n",
    "X_avd = extractor.features(13,\"data/avadh/\")\n",
    "X_avd= pd.DataFrame(X_avd)\n",
    "X_avd['Class']=5\n",
    "\n",
    "X_ksn = extractor.features(13,\"data/kasana/\")\n",
    "X_ksn= pd.DataFrame(X_ksn)\n",
    "X_ksn['Class']=6\n",
    "\n",
    "X_hrs = extractor.features(13,\"data/harsh/\")\n",
    "X_hrs= pd.DataFrame(X_hrs)\n",
    "X_hrs['Class']=7\n",
    "print('\\nData Extraction Complete.')\n",
    "\n",
    "#defining training and testing data\n",
    "X_nik_train = X_nik[:int(X_nik.shape[0]*0.8)]\n",
    "X_nik_test = X_nik[int(X_nik.shape[0]*0.8):]\n",
    "\n",
    "X_ark_train = X_ark[:int(X_ark.shape[0]*0.8)]\n",
    "X_ark_test = X_ark[int(X_ark.shape[0]*0.8):]\n",
    "\n",
    "X_prv_train = X_prv[:int(X_prv.shape[0]*0.8)]\n",
    "X_prv_test = X_prv[int(X_prv.shape[0]*0.8):]\n",
    "\n",
    "X_deb_train = X_deb[:int(X_deb.shape[0]*0.8)]\n",
    "X_deb_test = X_deb[int(X_deb.shape[0]*0.8):]\n",
    "\n",
    "X_arn_train = X_arn[:int(X_arn.shape[0]*0.8)]\n",
    "X_arn_test = X_arn[int(X_arn.shape[0]*0.8):]\n",
    "\n",
    "X_avd_train = X_avd[:int(X_avd.shape[0]*0.8)]\n",
    "X_avd_test = X_avd[int(X_avd.shape[0]*0.8):]\n",
    "\n",
    "X_ksn_train = X_ksn[:int(X_ksn.shape[0]*0.8)]\n",
    "X_ksn_test = X_ksn[int(X_ksn.shape[0]*0.8):]\n",
    "\n",
    "X_hrs_train = X_hrs[:int(X_hrs.shape[0]*0.8)]\n",
    "X_hrs_test = X_hrs[int(X_hrs.shape[0]*0.8):]\n",
    "\n",
    "X_train=X_nik_train.append([X_ark_train,X_prv_train,X_deb_train,X_arn_train,X_avd_train,X_ksn_train,X_hrs_train])\n",
    "X_test=X_nik_test.append([X_ark_test,X_prv_test,X_deb_test,X_arn_test,X_avd_test,X_ksn_test,X_hrs_test])\n",
    "\n",
    "y_train=X_train[['Class']]\n",
    "y_test=X_test[['Class']]\n",
    "X_data=X_train.append(X_test)\n",
    "X_data = X_data.reset_index(drop=True)\n",
    "y_data=y_train.append(y_test)\n",
    "y_data = y_data.reset_index(drop=True)\n",
    "print('\\nPre-processing Done.')\n",
    "\n",
    "print('\\nCount of different classes in Train set:')\n",
    "print(X_train['Class'].value_counts())\n",
    "\n",
    "print('\\nCount of different classes in Test set:')\n",
    "print(X_test['Class'].value_counts())\n",
    "\n",
    "feats=[c for c in X_train.columns if c!='Class']\n",
    "\n",
    "# Train classifier\n",
    "print('\\nImplementing Gaussian Naive Bayes Model.')\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(\n",
    "    X_train[feats].values,\n",
    "    y_train['Class']\n",
    ")\n",
    "y_pred = gnb.predict(X_test[feats].values)\n",
    "\n",
    "print(\"\\nNumber of mislabeled points out of a total {} points : {}, Accuracy: {:05.5f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (X_test[\"Class\"] != y_pred).sum(),\n",
    "          100*(1-(X_test[\"Class\"] != y_pred).sum()/X_test.shape[0])\n",
    "))\n",
    "\n",
    "#five fold cross validation\n",
    "cv = KFold(n_splits=5)\n",
    "clf = GaussianNB()\n",
    "X_data=X_data.values\n",
    "y_data=y_data.values\n",
    "accuracy=0\n",
    "for traincv, testcv in cv.split(X_data):\n",
    "        clf.fit(X_data[traincv], y_data[traincv])\n",
    "        train_predictions = clf.predict(X_data[testcv])\n",
    "        acc = accuracy_score(y_data[testcv], train_predictions)\n",
    "        accuracy+= acc\n",
    "        #print(accuracy)\n",
    "\n",
    "print('\\n5 Fold Cross Validation Accuracy on Training Set: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 1 extracted\n",
      "\n",
      "Dataset 2 extracted\n",
      "\n",
      "Dataset 3 extracted\n",
      "\n",
      "Dataset 4 extracted\n",
      "\n",
      "Dataset 5 extracted\n",
      "\n",
      "Dataset 6 extracted\n",
      "\n",
      "Dataset 7 extracted\n",
      "\n",
      "Dataset 8 extracted\n",
      "\n",
      "Dataset 9 extracted\n",
      "\n",
      "Data Extraction Complete.\n",
      "\n",
      "Pre-processing Done.\n",
      "\n",
      "Count of different classes in Train set:\n",
      "7    22225\n",
      "5    10792\n",
      "8     3153\n",
      "2     3101\n",
      "3     1004\n",
      "1      769\n",
      "4      651\n",
      "0      520\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Count of different classes in Test set:\n",
      "7    25457\n",
      "5     2699\n",
      "8      789\n",
      "2      776\n",
      "3      251\n",
      "1      193\n",
      "4      163\n",
      "0      131\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "Implementing Gaussian Naive Bayes Model.\n",
      "\n",
      "Number of mislabeled points out of a total 30459 points : 2207, Accuracy: 92.75419%\n",
      "\n",
      "5 Fold Cross Validation Accuracy on Training Set: 4.033711730306157\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import extractor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "\n",
    "# data extraction\n",
    "X_nik = extractor.features(13,\"data/nikhil/\")\n",
    "X_nik= pd.DataFrame(X_nik)\n",
    "X_nik['Class']=0\n",
    "print('\\nDataset 1 extracted')\n",
    "\n",
    "X_ark = extractor.features(13,\"data/arka/\")\n",
    "X_ark= pd.DataFrame(X_ark)\n",
    "X_ark['Class']=1\n",
    "print('\\nDataset 2 extracted')\n",
    "\n",
    "X_prv = extractor.features(13,\"data/prativa/\")\n",
    "X_prv= pd.DataFrame(X_prv)\n",
    "X_prv['Class']=2\n",
    "print('\\nDataset 3 extracted')\n",
    "\n",
    "X_deb = extractor.features(13,\"data/debalina/\")\n",
    "X_deb= pd.DataFrame(X_deb)\n",
    "X_deb['Class']=3\n",
    "print('\\nDataset 4 extracted')\n",
    "\n",
    "X_arn = extractor.features(13,\"data/aryendra/\")\n",
    "X_arn= pd.DataFrame(X_arn)\n",
    "X_arn['Class']=4\n",
    "print('\\nDataset 5 extracted')\n",
    "\n",
    "X_avd = extractor.features(13,\"data/avadh/\")\n",
    "X_avd= pd.DataFrame(X_avd)\n",
    "X_avd['Class']=5\n",
    "print('\\nDataset 6 extracted')\n",
    "\n",
    "X_ksn = extractor.features(13,\"data/kasana/\")\n",
    "X_ksn= pd.DataFrame(X_ksn)\n",
    "X_ksn['Class']=6\n",
    "print('\\nDataset 7 extracted')\n",
    "\n",
    "X_hrs = extractor.features(13,\"data/harsh/\")\n",
    "X_hrs= pd.DataFrame(X_hrs)\n",
    "X_hrs['Class']=7\n",
    "print('\\nDataset 8 extracted')\n",
    "\n",
    "X_dhn = extractor.features(13,\"data/dhananjay/\")\n",
    "X_dhn= pd.DataFrame(X_ksn)\n",
    "X_dhn['Class']=8\n",
    "print('\\nDataset 9 extracted')\n",
    "\n",
    "print('\\nData Extraction Complete.')\n",
    "\n",
    "#defining training and testing data\n",
    "X_nik_train = X_nik[:int(X_nik.shape[0]*0.8)]\n",
    "X_nik_test = X_nik[int(X_nik.shape[0]*0.8):]\n",
    "\n",
    "X_ark_train = X_ark[:int(X_ark.shape[0]*0.8)]\n",
    "X_ark_test = X_ark[int(X_ark.shape[0]*0.8):]\n",
    "\n",
    "X_prv_train = X_prv[:int(X_prv.shape[0]*0.8)]\n",
    "X_prv_test = X_prv[int(X_prv.shape[0]*0.8):]\n",
    "\n",
    "X_deb_train = X_deb[:int(X_deb.shape[0]*0.8)]\n",
    "X_deb_test = X_deb[int(X_deb.shape[0]*0.8):]\n",
    "\n",
    "X_arn_train = X_arn[:int(X_arn.shape[0]*0.8)]\n",
    "X_arn_test = X_arn[int(X_arn.shape[0]*0.8):]\n",
    "\n",
    "X_avd_train = X_avd[:int(X_avd.shape[0]*0.8)]\n",
    "X_avd_test = X_avd[int(X_avd.shape[0]*0.8):]\n",
    "\n",
    "X_ksn_train = X_ksn[:int(X_ksn.shape[0]*0.8)]\n",
    "X_ksn_test = X_ksn[int(X_ksn.shape[0]*0.8):]\n",
    "\n",
    "X_hrs_train = X_hrs[:int(X_hrs.shape[0]*0.8)]\n",
    "X_hrs_test = X_hrs[int(X_hrs.shape[0]*0.8):]\n",
    "\n",
    "X_dhn_train = X_hrs[:int(X_dhn.shape[0]*0.8)]\n",
    "X_dhn_test = X_hrs[int(X_dhn.shape[0]*0.8):]\n",
    "\n",
    "X_train=X_nik_train.append([X_ark_train,X_prv_train,X_deb_train,X_arn_train,X_avd_train,X_ksn_train,X_hrs_train, X_dhn_train])\n",
    "X_test=X_nik_test.append([X_ark_test,X_prv_test,X_deb_test,X_arn_test,X_avd_test,X_ksn_test,X_hrs_test, X_dhn_test])\n",
    "\n",
    "y_train=X_train[['Class']]\n",
    "y_test=X_test[['Class']]\n",
    "X_data=X_train.append(X_test)\n",
    "X_data = X_data.reset_index(drop=True)\n",
    "y_data=y_train.append(y_test)\n",
    "y_data = y_data.reset_index(drop=True)\n",
    "print('\\nPre-processing Done.')\n",
    "\n",
    "print('\\nCount of different classes in Train set:')\n",
    "print(X_train['Class'].value_counts())\n",
    "\n",
    "print('\\nCount of different classes in Test set:')\n",
    "print(X_test['Class'].value_counts())\n",
    "\n",
    "feats=[c for c in X_train.columns if c!='Class']\n",
    "\n",
    "# Train classifier\n",
    "print('\\nImplementing Gaussian Naive Bayes Model.')\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(\n",
    "    X_train[feats].values,\n",
    "    y_train['Class']\n",
    ")\n",
    "y_pred = gnb.predict(X_test[feats].values)\n",
    "\n",
    "print(\"\\nNumber of mislabeled points out of a total {} points : {}, Accuracy: {:05.5f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (X_test[\"Class\"] != y_pred).sum(),\n",
    "          100*(1-(X_test[\"Class\"] != y_pred).sum()/X_test.shape[0])\n",
    "))\n",
    "\n",
    "#five fold cross validation\n",
    "cv = KFold(n_splits=5)\n",
    "clf = GaussianNB()\n",
    "X_data=X_data.values\n",
    "y_data=y_data.values\n",
    "accuracy=0\n",
    "for traincv, testcv in cv.split(X_data):\n",
    "        clf.fit(X_data[traincv], y_data[traincv])\n",
    "        train_predictions = clf.predict(X_data[testcv])\n",
    "        acc = accuracy_score(y_data[testcv], train_predictions)\n",
    "        accuracy+= acc\n",
    "       \n",
    "\n",
    "print('\\n5 Fold Cross Validation Accuracy on Training Set: '+str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
